FROM nvcr.io/nvidia/tensorrt:22.12-py3
WORKDIR /app

RUN apt-get update -y && apt-get install -y \
    libsm6 \
    libxext6 \
    libopencv-dev \
    uvicorn \
    rustc \
    cargo \
    && rm -rf /var/lib/apt/lists/*

COPY requirements/requirements.sam.txt \
    requirements/requirements.clip.txt \
    requirements/requirements.http.txt \
    requirements/requirements.waf.txt \
    requirements/requirements.gpu.txt \
    requirements/requirements.gaze.txt \
    requirements/requirements.doctr.txt \
    requirements/requirements.groundingdino.txt \
    requirements/_requirements.txt \
    requirements/requirements.sdk.http.txt \
    ./

RUN pip install --upgrade pip  && pip install \
    --extra-index-url https://download.pytorch.org/whl/cu118 \
    --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-11/pypi/simple/ \
    -r _requirements.txt \
    -r requirements.sam.txt \
    -r requirements.clip.txt \
    -r requirements.http.txt \
    -r requirements.waf.txt \
    -r requirements.gpu.txt \
    -r requirements.gaze.txt \
    -r requirements.doctr.txt \
    -r requirements.groundingdino.txt \
    -r requirements.sdk.http.txt \
    "setuptools<=75.5.0" \
    --upgrade \
    && rm -rf ~/.cache/pip

WORKDIR /app/
COPY inference inference
COPY inference_sdk inference_sdk
COPY docker/config/gpu_http.py gpu_http.py


# RUN sudo apt install --only-upgrade libstdc++6
ENV CORE_MODEL_SAM2_ENABLED=true
ENV VERSION_CHECK_MODE=continuous
ENV ONNXRUNTIME_EXECUTION_PROVIDERS=TensorrtExecutionProvider
ENV REQUIRED_ONNX_PROVIDERS=TensorrtExecutionProvider
ENV ORT_TENSORRT_ENGINE_CACHE_ENABLE=1
ENV CORE_MODEL_SAM_ENABLED=False
ENV PROJECT=roboflow-platform
ENV NUM_WORKERS=1
ENV HOST=0.0.0.0
ENV PORT=9001
ENV WORKFLOWS_STEP_EXECUTION_MODE=local
ENV WORKFLOWS_MAX_CONCURRENT_STEPS=4
ENV API_LOGGING_ENABLED=True
ENV PYTHONPATH=/app/:${PYTHONPATH}
ENV PATH=/opt/miniconda/bin:$PATH
ENV CORE_MODEL_TROCR_ENABLED=false
ENV ENABLE_WORKFLOWS_PROFILING=True
ENV ENABLE_PROMETHEUS=True

ENTRYPOINT uvicorn gpu_http:app --workers $NUM_WORKERS --host $HOST --port $PORT